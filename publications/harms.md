---
title: "Responsible forecasting: identifying and typifying forecasting harms"
date: "2024-11-26"
author: Bahman Rostami-Tabar, Travis Greene, Galit Shmueli, Rob&nbsp;J&nbsp;Hyndman
arxiv: 2411.16531
categories: Unpublished
---

Data-driven organizations around the world routinely use forecasting methods to improve their planning and decision-making capabilities. Although much research exists on the harms resulting from traditional machine learning applications, little has specifically focused on the ethical impact of time series forecasting. Yet forecasting raises unique ethical issues due to the way it is used in different organizational contexts, supports different goals, and involves different data processing, model development, and evaluation pipelines. These differences make it difficult to apply machine learning harm taxonomies to common forecasting contexts. We leverage multiple interviews with expert industry practitioners and academic researchers to remedy this knowledge gap by cataloguing and analysing under-explored domains, applications, and scenarios where forecasting may cause harm, with the goal of developing a novel taxonomy of forecasting-specific harms. Inspired by Microsoft Azure taxonomy for responsible innovation, we combined a human-led inductive coding scheme with an AI-driven analysis centered on the extraction of key taxonomies of harm in forecasting. The taxonomy is designed to guide researchers and practitioners and encourage ethical reflection on the impact of their decisions during the forecasting process. A secondary objective is to create a research agenda focused on possible forecasting-related measures to mitigate harm. Our work extends the growing literature on machine learning harms by identifying unique forms of harm that may occur in forecasting.
