---
date: 2024-05-14
title: "Statistical Forecasting"
venue: Monash University FUTURES symposium
link: https://github.com/robjhyndman/statistical_forecasting/raw/main/statistical_forecasting.pdf
---

## Talk given as part of the Monash University FUTURES symposium

Statistical forecasting involves using historical data to predict future outcomes. The goal is to build a stochastic model that captures the underlying patterns in the data, and how those have changed over time, and use it to make predictions about future values. I have developed many statistical forecasting models that are now widely used in diverse domains including retail, energy, demography, and tourism.

The strength of statistical forecasting lies in its ability to provide quantifiable predictions based on historical data, and to include uncertainty in those predictions. Statistical forecasts are typically presented as probability distributions of future outcomes, which can be used to make decisions that account for the uncertainty in the predictions.

Most recently I have been developing tools that allow statistical forecasts to be produced for thousands of related time series, such as sales forecasts for individual products in a retail store, or electricity demand forecasts for small regions in a country. The disaggregated data tends to be noisy and sparse, and the models need to be able to share information across related series to make accurate predictions.

Because of the assumption that the future will continue to evolve similarly to the past, statistical forecasting tends to perform best when: (a) there is substantial historical data; (b) the underlying environment is relatively stable; and (c) the aim is to produce short-term forecasts. When there is limited historical data, or when the data generating process is subject to significant structural changes, statistical forecasting can struggle to make accurate predictions.

I am also interested in using statistical forecasting techniques to identify anomalies, such as sudden changes in the underlying process, or unusual patterns in the data. This can be useful for detecting fraud, monitoring the health of complex systems, or identifying recording errors in data.
