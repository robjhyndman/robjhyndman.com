{
  "hash": "0a409aa8189b9f48494d77db58cf1769",
  "result": {
    "markdown": "---\ndate: 2019-09-16\nslug: fbtsa\ntitle: \"Feature-based time series analysis\"\ncategories:\n- time series\n- graphics\n- statistics\n- R\n- tidyverts\n- anomalies\n- data science\nimage: index_files/figure-html/features-plot-1.png\n---\n\n\n\n\nIn my [last post](https://robjhyndman.com/hyndsight/feasts/), I showed how the `feasts` package can be used to produce various time series graphics.\n\nThe `feasts` package also includes functions for computing FEatures And Statistics from Time Series (hence the name). In this post I will give three examples of how these might be used.\n\n\n::: {.cell hash='index_cache/html/loadpackages_845d2d322917cf4b4823b6c54c839c4c'}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(tsibble)\nlibrary(feasts)\n```\n:::\n\n\n## Exploring Australian tourism data\n\nI used this example in [my talk at useR!2019 in Toulouse](https://robjhyndman.com/seminars/isf-feasts/), and it is also the basis of [a vignette in the package](http://feasts.tidyverts.org/articles/feasts.html), and a recent [blog post by Mitchell O'Hara-Wild](https://www.mitchelloharawild.com/blog/feasts/). The data set contains domestic tourist visitor nights in Australia, disaggregated by State, Region and Purpose.\n\n\n::: {.cell hash='index_cache/html/tourismdata_d40689a06461e215b754ab4ecd502364'}\n\n```{.r .cell-code}\ntourism\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tsibble: 24,320 x 5 [1Q]\n# Key:       Region, State, Purpose [304]\n   Quarter Region   State           Purpose  Trips\n     <qtr> <chr>    <chr>           <chr>    <dbl>\n 1 1998 Q1 Adelaide South Australia Business  135.\n 2 1998 Q2 Adelaide South Australia Business  110.\n 3 1998 Q3 Adelaide South Australia Business  166.\n 4 1998 Q4 Adelaide South Australia Business  127.\n 5 1999 Q1 Adelaide South Australia Business  137.\n 6 1999 Q2 Adelaide South Australia Business  200.\n 7 1999 Q3 Adelaide South Australia Business  169.\n 8 1999 Q4 Adelaide South Australia Business  134.\n 9 2000 Q1 Adelaide South Australia Business  154.\n10 2000 Q2 Adelaide South Australia Business  169.\n# … with 24,310 more rows\n```\n:::\n:::\n\n\nAn example of a feature would be the autocorrelation function at lag 1 --- it is a numerical summary capturing some aspect of the time series. Autocorrelations at other lags are also features, as are the autocorrelations of the first differenced series, or the seasonally differenced series, etc. Another example of a feature is the strength of seasonality of a time series, as measured by $1-\\text{Var}(R_t)/\\text{Var}(S_t+R_t)$ where $S_t$ is the seasonal component and $R_t$ is the remainder component in an STL decomposition. Values close to 1 indicate a highly seasonal time series, while values close to 0 indicate a time series with little seasonality.\n\nThe `feasts` package has some inbuilt feature calculation functions. For example `coef_hurst` will calculate the Hurst coefficient of a time series and `feat_spectral` will compute the spectral entropy of a time series. To apply these to all series in the `tourism` data set, we can use the `features` function like this.\n\n\n::: {.cell hash='index_cache/html/entropy_014df036850d8974db840498c888a2b2'}\n\n```{.r .cell-code}\ntourism %>% features(Trips, list(coef_hurst, feat_spectral))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 304 × 5\n   Region         State              Purpose  coef_hurst spectral_entropy\n   <chr>          <chr>              <chr>         <dbl>            <dbl>\n 1 Adelaide       South Australia    Business      0.571            0.843\n 2 Adelaide       South Australia    Holiday       0.558            0.753\n 3 Adelaide       South Australia    Other         0.862            0.793\n 4 Adelaide       South Australia    Visiting      0.583            0.768\n 5 Adelaide Hills South Australia    Business      0.555            0.991\n 6 Adelaide Hills South Australia    Holiday       0.651            0.928\n 7 Adelaide Hills South Australia    Other         0.672            0.913\n 8 Adelaide Hills South Australia    Visiting      0.653            1    \n 9 Alice Springs  Northern Territory Business      0.713            0.944\n10 Alice Springs  Northern Territory Holiday       0.500            0.544\n# … with 294 more rows\n```\n:::\n:::\n\n\nThere are also functions which produce collections of features based on tags. For example, `feature_set(tags=\"acf\")` will produce 7 features based on various autocorrelation coefficients, while `feature_set(tags=\"stl\")` produces 7 features based on an STL decomposition of a time series, including the strength of seasonality mentioned above.\n\n\n::: {.cell hash='index_cache/html/features_64ac422b9e9ebe10c3033ec9e0c8fa42'}\n\n```{.r .cell-code}\ntourism %>% features(Trips, feature_set(tags=\"stl\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 304 × 12\n   Region  State Purpose trend…¹ seaso…² seaso…³ seaso…⁴ spiki…⁵ linea…⁶ curva…⁷\n   <chr>   <chr> <chr>     <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n 1 Adelai… Sout… Busine…   0.464   0.407       3       1 1.58e+2  -5.31   71.6  \n 2 Adelai… Sout… Holiday   0.554   0.619       1       2 9.17e+0  49.0    78.7  \n 3 Adelai… Sout… Other     0.746   0.202       2       1 2.10e+0  95.1    43.4  \n 4 Adelai… Sout… Visiti…   0.435   0.452       1       3 5.61e+1  34.6    71.4  \n 5 Adelai… Sout… Busine…   0.464   0.179       3       0 1.03e-1   0.968  -3.22 \n 6 Adelai… Sout… Holiday   0.528   0.296       2       1 1.77e-1  10.5    24.0  \n 7 Adelai… Sout… Other     0.593   0.404       2       2 4.44e-4   4.28    3.19 \n 8 Adelai… Sout… Visiti…   0.488   0.254       0       3 6.50e+0  34.2    -0.529\n 9 Alice … Nort… Busine…   0.534   0.251       0       1 1.69e-1  23.8    19.5  \n10 Alice … Nort… Holiday   0.381   0.832       3       1 7.39e-1 -19.6    10.5  \n# … with 294 more rows, 2 more variables: stl_e_acf1 <dbl>, stl_e_acf10 <dbl>,\n#   and abbreviated variable names ¹​trend_strength, ²​seasonal_strength_year,\n#   ³​seasonal_peak_year, ⁴​seasonal_trough_year, ⁵​spikiness, ⁶​linearity,\n#   ⁷​curvature\n```\n:::\n:::\n\n\nWe can then use these features in plots to identify what type of series are heavily trended and what are most seasonal.\n\n\n::: {.cell hash='index_cache/html/features-plot_914e90c7119634096dfc9769f75bff96'}\n\n```{.r .cell-code}\ntourism %>% features(Trips, feature_set(tags=\"stl\")) %>%\n  ggplot(aes(x=trend_strength, y=seasonal_strength_year, col=Purpose)) +\n    geom_point() + facet_wrap(vars(State))\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/features-plot-1.png){width=672}\n:::\n:::\n\n\nClearly, holiday series are most seasonal which is unsurprising. The strongest trends tend to be in Western Australia.\n\nThe most seasonal series can also be easily identified and plotted.\n\n\n::: {.cell hash='index_cache/html/extreme_82e9e815ee068d3ca327c3e6789717b9'}\n\n```{.r .cell-code}\ntourism %>%\n  features(Trips, feature_set(tags=\"stl\")) %>%\n  filter(seasonal_strength_year == max(seasonal_strength_year)) %>%\n  left_join(tourism, by = c(\"State\",\"Region\",\"Purpose\")) %>%\n  ggplot(aes(x = Quarter, y = Trips)) + geom_line() +\n    facet_grid(vars(State,Region,Purpose))\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/extreme-1.png){width=672}\n:::\n:::\n\n\nThis is holiday trips to the most popular ski region of Australia.\n\nThe `feasts` package currently includes 42 features which can all be computed in one line like this.\n\n\n::: {.cell hash='index_cache/html/all_features_6020e2ccb56f9a553c03d3a66dfd2a1c'}\n\n```{.r .cell-code}\n# Compute features\ntourism_features <- tourism %>%\n  features(Trips, feature_set(pkgs=\"feasts\"))\n```\n:::\n\n\nUnusual time series can be identified by first doing a principal components decomposition\n\n\n::: {.cell hash='index_cache/html/pca_a67315e86e0698eacb6eb005c5d044f6'}\n\n```{.r .cell-code}\npcs <- tourism_features %>%\n  select(-State, -Region, -Purpose) %>%\n  prcomp(scale=TRUE) %>%\n  augment(tourism_features)\npcs %>%\n  ggplot(aes(x=.fittedPC1, y=.fittedPC2, col=Purpose)) +\n  geom_point() + theme(aspect.ratio=1)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/pca-1.png){width=672}\n:::\n:::\n\n\nWe can then identify some unusual series.\n\n\n::: {.cell hash='index_cache/html/pca_outliers_1805ab2ae4a784fadad7809e51b41bc8'}\n\n```{.r .cell-code}\npcs %>%\n  filter(.fittedPC1 > 10.5) %>%\n  select(Region, State, Purpose, .fittedPC1, .fittedPC2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 4 × 5\n  Region                 State             Purpose  .fittedPC1 .fittedPC2\n  <chr>                  <chr>             <chr>         <dbl>      <dbl>\n1 Australia's North West Western Australia Business       13.4    -11.3  \n2 Australia's South West Western Australia Holiday        10.9      0.880\n3 Melbourne              Victoria          Holiday        12.3    -10.4  \n4 South Coast            New South Wales   Holiday        11.9      9.42 \n```\n:::\n:::\n\n\n## Replicating Hyndman, Wang and Laptev (2015)\n\nI used a similar approach to identifying outliers in my [ICDM 2015 paper with Earo Wang and Nikolay Laptev](https://robjhyndman.com/publications/icdm2015/). In that paper, we used hourly data on thousands of mail servers from Yahoo.\n\nThe data is stored in the `tsfeatures` package as an `mts` object. Unfortunately, `mts` and `ts` objects are particularly bad at handling hourly and other sub-daily data, as time is stored numerically and the precision is not sufficient to always work properly. So we need to do a little work to create a properly formulated tsibble.\n\n\n::: {.cell hash='index_cache/html/yahoodata_2bb9c0a5b55e14c74fce7de156ecaf18'}\n\n```{.r .cell-code}\nyahoo <- tsfeatures::yahoo_data() %>%\n  as_tsibble() %>%\n  mutate(\n    Time = hms::hms(day = trunc(index) - 1L,\n                    hour = as.integer((round(24*(index-1))) %% 24))\n  ) %>%\n  as_tsibble(index = Time, key=key) %>%\n  select(Time, key, value)\n```\n:::\n\n\nThe `key` variable here identifies the particular server and measurement variable on that server. There are 1748 such time series, each with 1437 (almost 60 days) observations.\n\nNow we create the features on all series, matching the original paper as closely as possible. There are a few small differences due to different choices in how features are computed, but they make little difference to the results.\n\nThe features are computed in two groups --- the first group uses the original data, while the second group uses the scaled data.\n\n\n::: {.cell hash='index_cache/html/yahoo_features_ea0872f3a38fbbece39e444a8320590c'}\n\n```{.r .cell-code}\nyahoo_features <- bind_cols(\n    yahoo %>% features(value, features=list(\n      mean = ~ mean(., na.rm = TRUE),\n      var = ~ var(., na.rm = TRUE)\n    )),\n    yahoo %>% features(scale(value), features = list(\n      ~ feat_acf(.),\n      ~ feat_spectral(.),\n      ~ longest_flat_spot(.),\n      ~ n_crossing_points(.),\n      ~ var_tiled_var(., .period = 24, .size = 24),\n      ~ shift_level_max(., .period = 24, .size = 24),\n      ~ shift_var_max(., .period = 24, .size = 24),\n      ~ shift_kl_max(., .period = 24, .size = 48),\n      ~ feat_stl(., .period = 24, s.window = \"periodic\", robust = TRUE)\n    ))\n  ) %>%\n  rename(\n    lumpiness = var_tiled_var,\n    key = key...1\n  ) %>%\n  select(key, mean, var, acf1, trend_strength,\n         seasonal_strength_24, linearity, curvature,\n         seasonal_peak_24, seasonal_trough_24,\n         spectral_entropy, lumpiness, spikiness,\n         shift_level_max, shift_var_max,\n         longest_flat_spot, n_crossing_points,\n         shift_kl_max, shift_kl_index)\n```\n:::\n\n\nNow we can compute the principal components.\n\n\n::: {.cell hash='index_cache/html/yahoo_pca_241637a7626395a5cb92bd6cc435c0e7'}\n\n```{.r .cell-code}\nhwl_pca <- yahoo_features %>%\n  select(-key) %>%\n  na.omit() %>%\n  prcomp(scale=TRUE) %>%\n  augment(na.omit(yahoo_features))\nhwl_pca %>%\n  as_tibble() %>%\n  ggplot(aes(x=.fittedPC1, y=.fittedPC2)) +\n    geom_point()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/yahoo_pca-1.png){width=672}\n:::\n:::\n\n\nA useful plot for identifying the outlying observations is an HDR scatterplot which highlights regions of high density, and identifies outliers as those observations in low density regions. The red dots are the 1% highest density observations, the orange dots are in the 50% region, the yellow dots are in the 99% regions, while those shown in black are the 1% most \"unusual\" observations (having the lowest bivariate density on this plot.) The five most outlying points are highlighted by their row numbers.\n\n\n::: {.cell hash='index_cache/html/hdrplot_54afb7729e946ca8732fd9c49d819269'}\n\n```{.r .cell-code}\nhdrcde::hdrscatterplot(hwl_pca$.fittedPC1, hwl_pca$.fittedPC2, noutliers=5)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/hdrplot-1.png){width=672}\n:::\n:::\n\n\n## Replicating Kang, Hyndman and Smith-Miles (2017)\n\nAnother paper that uses features is this [IJF paper from 2017](https://robjhyndman.com/publications/ts-feature-space/) in which we explored the feature space of the M3 time series data.\n\nFirst we need to create several tsibbles, corresponding to the different seasonal periods in the M3 data.\n\n\n::: {.cell hash='index_cache/html/m3data_1cee9a32b375548474a00d660adbe58e'}\n\n```{.r .cell-code}\nm3totsibble <- function(z) {\n  bind_rows(\n    as_tsibble(z$x) %>% mutate(Type=\"Training\") %>% as_tibble(),\n    as_tsibble(z$xx) %>% mutate(Type=\"Test\") %>% as_tibble()\n  ) %>%\n  mutate(\n    st = z$st,\n    type = z$type,\n    period = z$period,\n    description = z$description,\n    sn = z$sn,\n  )\n}\nm3yearly <- Mcomp::M3 %>%\n  subset(\"yearly\") %>%\n  purrr::map_dfr(m3totsibble) %>%\n  as_tsibble(index=index, key=c(sn,period,st))\nm3quarterly <- Mcomp::M3 %>%\n  subset(\"quarterly\") %>%\n  purrr::map_dfr(m3totsibble) %>%\n  mutate(index = yearquarter(index)) %>%\n  as_tsibble(index=index, key=c(sn,period,st))\nm3monthly <- Mcomp::M3 %>%\n  subset(\"monthly\") %>%\n  purrr::map_dfr(m3totsibble) %>%\n  mutate(index = yearmonth(index)) %>%\n  as_tsibble(index=index, key=c(sn,period,st))\nm3other <- Mcomp::M3 %>%\n  subset(\"other\") %>%\n  purrr::map_dfr(m3totsibble) %>%\n  as_tsibble(index=index, key=c(sn,period,st))\n```\n:::\n\n\nThere are some bespoke features used by Kang et al (IJF 2017), so rather than use the inbuilt `feasts` functions, we can create our own feature calculation function.\n\n\n::: {.cell hash='index_cache/html/m3_features_97b830a29d93a9695900aee61b13501f'}\n\n```{.r .cell-code}\nkhs_stl <- function(x, period) {\n  output <- c(frequency=period, feat_spectral(x))\n  lambda <- forecast::BoxCox.lambda(ts(x, frequency=period),\n                      lower=0, upper=1, method='loglik')\n  stlfeatures <- feat_stl(box_cox(x, lambda), .period=period,\n      s.window='periodic', robust=TRUE)\n  output <- c(output, stlfeatures, lambda=lambda)\n  if(period==1L)\n    output <- c(output, seasonal_strength=0)\n  return(output)\n}\nm3_features <- bind_rows(\n    m3yearly %>% features(value, features=list(~ khs_stl(.,1))),\n    m3quarterly %>% features(value, features=list(~ khs_stl(.,4))) %>%\n      rename(seasonal_strength = seasonal_strength_4),\n    m3monthly %>% features(value, features=list(~ khs_stl(.,12))) %>%\n      rename(seasonal_strength = seasonal_strength_12),\n    m3other %>% features(value, features=list(~ khs_stl(.,1)))\n  ) %>%\n  select(sn, spectral_entropy, trend_strength, seasonal_strength,\n         frequency, stl_e_acf1, lambda)\n```\n:::\n\n\nFinally we plot the first two principal components of the feature space.\n\n\n::: {.cell hash='index_cache/html/m3_pca_f81e55b4171379c3f4ae86ef8102f3e2'}\n\n```{.r .cell-code}\nm3_features %>%\n  select(-sn) %>%\n  prcomp(scale=TRUE) %>%\n  augment(m3_features) %>%\n  ggplot(aes(x=.fittedPC1, y=.fittedPC2)) +\n    geom_point(aes(color = factor(frequency)))\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/m3_pca-1.png){width=672}\n:::\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}