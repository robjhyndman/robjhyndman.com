{
  "hash": "1d6d97457bcc69a4c1d7b401180f357c",
  "result": {
    "markdown": "---\ndate: 2016-06-01 07:22:52+00:00\nslug: forecast7-part-2\ntitle: Forecast v7 (part 2)\ncategories:\n- forecasting\n- graphics\n- R\n- time series\n---\n\n\nAs mentioned in [my previous post on the forecast package v7](https://robjhyndman.com/hyndsight/forecast7-ggplot2/), the most visible feature was the introduction of [ggplot2 graphics](https://ggplot2.tidyverse.org/). This post briefly summarizes the remaining new features of forecast v7.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(forecast)\nlibrary(ggplot2)\n```\n:::\n\n\n### tslm rewritten\n\nThe `tslm` function is designed to fit linear models to time series data. It is intended to approximately mimic `lm` (and  calls `lm` to do the estimation), but to package the output to remember the `ts` attributes. It also handles some predictor variables automatically, notably `trend` and `season`. The re-write means that `tslm` now handles functions as predictors, including `fourier`.\n\n\n::: {.cell hash='index_cache/html/unnamed-chunk-2_c77a57a1708d4a52bceb00a48ddcdeb6'}\n\n```{.r .cell-code}\ndeaths.lm  <- tslm(mdeaths ~ trend + fourier(mdeaths,3))\nmdeaths.fcast <- forecast(deaths.lm,\n    data.frame(fourier(mdeaths,3,36)))\nautoplot(mdeaths.fcast)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n:::\n\n\nNote that `fourier` now takes 3 arguments. The first is the series, which is only used to grab the seasonal period and the `tsp` attribute. The second argument `K` is the number of Fourier harmonics to compute. If the third argument `h` is `NULL` (the default), the function returns Fourier terms for the times of the historical observations. But if `h` is a positive integer, the function returns Fourier terms for the next `h` time periods after the end of the historical data.\n\nThe `lm` function has long allowed a matrix to be passed and independent linear models fitted to each column. The new `tslm` function also allows this now.\n\n### Bias adjustment for Box-Cox transformations\n\nAlmost all modelling and forecasting functions in the package allow Box-Cox transformations to be applied before the model is fitted, and for the forecasts to be back transformed. This will give median forecasts on the original scale, as [I've explained before](https://robjhyndman.com/hyndsight/backtransforming/).\n\nThere is now an option to adjust the forecasts so they are means rather than medians, but setting `biasadj=TRUE` whenever the forecasts are computed. I will probably make this the default in some future version, but for now the default is `biasadj=FALSE` so the forecasts are actually medians.\n\n\n::: {.cell hash='index_cache/html/unnamed-chunk-3_5baa3d141f319e3b8d526d3d9a16000d'}\n\n```{.r .cell-code}\nlibrary(fpp, quietly=TRUE)\nfit <- ets(eggs, model=\"AAN\", lambda=0)\nfc1 <- forecast(fit, biasadj=TRUE, h=20, level=95)\nfc2 <- forecast(fit, biasadj=FALSE, h=20)\ncols <- c(\"Mean\"=\"#0000ee\",\"Median\"=\"#ee0000\")\nautoplot(fc1) + ylab(\"Price\") + xlab(\"Year\") +\n  autolayer(fc2, PI=FALSE, series=\"Median\") +\n  autolayer(fc1, PI=FALSE, series=\"Mean\") +\n  guides(fill=FALSE) +\n  scale_colour_manual(name=\"Forecasts\",values=cols)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: `guides(<scale> = FALSE)` is deprecated. Please use `guides(<scale> =\n\"none\")` instead.\n```\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n\n### A new Ccf function\n\nCross-correlations can now be computed using `Ccf`, mimicing `ccf` except that the axes are more informative.\n\nThe `Acf` function now handles multivariate time series, with cross-correlation functions computed as well as the ACFs of each series.\n\n### Covariates in neural net AR models\n\nThe `nnetar` function allows neural networks to be applied to time series data by building a nonlinear autoregressive model. A new feature allows additional inputs to be included in the model.\n\n### Better subsetting of time series\n\n`subset.ts` allows quite sophisticated subsetting of a time series. For example\n\n\n::: {.cell hash='index_cache/html/unnamed-chunk-4_15726f39f13d24fd45e09757a9023ccb'}\n\n```{.r .cell-code}\nplot(subset(gas,month=\"November\"))\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n\n```{.r .cell-code}\nsubset(woolyrnq,quarter=3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nTime Series:\nStart = 1965.5 \nEnd = 1994.5 \nFrequency = 1 \n [1] 6633 6730 6946 6915 7190 7105 6840 7819 7045 5540 5906 5505 5318 5466 5696\n[16] 5341 5464 5129 5524 6080 6540 6339 6590 6077 5146 5127 5222 4954 5309 6396\n```\n:::\n:::\n\n\nThis is now substantially more robust than it used to be.\n\n### What's next?\n\nThe next major release will probably be around the end of 2016. On the to-do list are:\n\n  * **In-sample multi-step fitted values**. Currently `fitted` returns in-sample one-step forecasts. A new argument to `fitted` will allow multi-step forecasts of the training data.\n\n  * **Applying fitted models to new data sets**. A related issue is to take an estimated model and apply it to some new data without re-estimating parameters. This is already possible with `Arima` and `ets` models. It will be extended to many more model types.\n\n  * **Better choice of seasonal differencing**. Currently `auto.arima` does a pretty good job at finding the orders of a model, and the number of first-differences required, but it does not handle seasonal differences well. It often selects 0 differences, when I think it should select 1 difference. So I tend to over-ride the automatic choice with `auto.arima(x, D=1)`. I will attempt to find some better tests of seasonal unit roots than those that are currently implemented.\n\n  * **Prediction intervals for NNAR forecasts**. The forecasts obtained using a NNAR model (via the `nnetar` function) do not have prediction intervals because there is no underlying stochastic model on which to base them. However, there are ways of computing the uncertainty using simulation, and I hope to implement something like that for the next version.\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}