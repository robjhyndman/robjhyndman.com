{
  "hash": "528953c128a606e0f482e61127f9ce5d",
  "result": {
    "markdown": "---\ntitle: \"Time Series in R: Forecasting and Visualisation\"\nslug: forecasting-medascin\naliases:\n  - /forecasting-medascin/\nauthor: \"Rob J Hyndman & Earo Wang\"\ndate: 2017-05-29\ndraft: no\n---\n\n\nThis is a one-day workshop given as part of the [Melbourne Data Science Week](http://www.datasciencemelbourne.com/medascin/).\n\n**Date**: 29 May 2017<br>\n**Presenters**: Rob J Hyndman and Earo Wang<br>\n**Location**: KPMG, Tower Two, Collins Square, 727 Collins St, Melbourne\n\n## Prerequisites\n\nPlease bring your own laptop with a recent version of R installed, along with the following packages and their dependencies:\n\n  * `devtools`\n  * `fpp2`\n  * `knitr`\n  * `plotly`\n  * `shiny`\n  * `tidyverse`\n\nParticipants will be assumed to be familiar with basic statistical tools such as multiple regression, but no knowledge of time series or forecasting will be assumed.\n\n## Reference\n\n<a href=\"http://OTexts.org/fpp2/\" target=\"_new\">\n![alt text](/medascin/fppcover-small.jpg)\n</a>\n\n## Need help with R?\n\n* [Base R cheatsheet](https://www.rstudio.com/wp-content/uploads/2016/10/r-cheat-sheet-3.pdf)\n* [Datacamp: Introduction to R course](https://www.datacamp.com/courses/free-introduction-to-r)\n* [Help with Rmarkdown](http://rmarkdown.rstudio.com/lesson-2.html)\n* [Rmarkdown cheatsheet](https://www.rstudio.com/wp-content/uploads/2016/03/rmarkdown-cheatsheet-2.0.pdf)\n\n## Program\n\n<table border=1 cellpadding=2 cellspacing=5 width=100%>\n<col width=\"15%\">\n<col width=\"70%\">\n<col width=\"15%\">\n<tr>\n  <td>08.30 - 09.00</td>\n  <td style=\"vertical-align: middle;\">Registration and welcome</td>\n  <td style=\"vertical-align: middle;\"><a href=\"/medascin/0-Intro.pdf\" target=\"_new\">Slides</a></td>\n</tr>\n  <td>09.00 - 10.30</td>\n  <td><b>Time series and R, Time series graphics</b><br>\n  <a href=\"#Lab1\">Lab Sessions 1-2</a></td>\n  <td style=\"vertical-align: middle;\"><a href=\"/medascin/1-time-series-graphics.pdf\" target=\"_new\">Slides</a></td>\n</tr>\n<tr>\n  <td>10.30 - 11.00</td>\n  <td style=\"vertical-align: middle;\"><em>Morning tea</em></td><td></td>\n</tr>\n<tr>\n  <td>11.00 - 12.30</td>\n  <td><b>Visualising temporal data</b><br>\n  <a href=\"#Lab3\">Lab Sessions 3-4</a></td>\n  <td style=\"vertical-align: middle;\"><a href=\"http://slides.earo.me/medascin17/\" target=\"_new\">Slides</a></td>\n</tr>\n<tr>\n  <td>12.30 - 13.30</td>\n  <td style=\"vertical-align: middle;\"><em>Lunch</em></td><td></td>\n</tr>\n<tr>\n  <td>13.30 - 15.00</td>\n  <td><b>Some automatic forecasting algorithms</b><br>\n  <a href=\"#Lab5\">Lab Sessions 5-6</a></td>\n  <td style=\"vertical-align: middle;\"><a href=\"/medascin/3-automatic-forecasting.pdf\" target=\"_new\">Slides</a></td>\n</tr>\n<tr>\n  <td>15.00 - 15.30</td>\n  <td style=\"vertical-align: middle;\"><em>Afternoon tea</em></td><td></td>\n</tr>\n<tr>\n  <td>15.30 - 16.45</td>\n  <td><b>Forecast evaluation</b><br>\n  <a href=\"#Lab7\">Lab Sessions 7-8</a></td>\n  <td style=\"vertical-align: middle;\"><a href=\"/medascin/4-forecast-evaluation.pdf\" target=\"_new\">Slides</a></td>\n</tr>\n<tr>\n  <td>16.45 - 17:00</td>\n  <td style=\"vertical-align: middle;\">Wrap up</td>\n  <td style=\"vertical-align: middle;\"><a href=\"/medascin/WrapUp.pdf\" target=\"_new\">Slides</a></td>\n</tr>\n</table>\n\n## Lab sessions\n\n<a name=\"Lab1\"></a>\n\n### Lab Session 1\n\n1. Download the [`Retail.Rmd`](/medascin/Retail.Rmd) file. This will be used for all analysis of the retail data.\n\n2. Download the [monthly Australian retail data](https://robjhyndman.com/data/retail.xlsx). These represent retail sales in various categories for different Australian states.\n\n3.  Read the data into R and choose *one* of the series. This time series will be used throughout the workshop in lab sessions 1--2, and 5--10.\n\n    Please script this, don't just use the Rstudio click-and-point interface. That way you can save the results for easy replication later.\n\n    You will need the `read_excel` function from the `readxl` package:\n\n    ```r\n    retaildata <- readxl::read_excel(\"retail.xlsx\", skip = 1)\n    mytimeseries <- ts(retaildata[[\"A3349873A\"]], frequency=12, start=c(1982,4))\n    autoplot(mytimeseries)\n    ```\n\n    [Replace the column name with your own chosen column.]\n\n<a name=\"Lab2\"></a>\n\n### Lab Session 2\n\nThe following graphics functions have been introduced:\n\n```r\nautoplot, ggseasonplot, ggmonthplot, gglagplot, ggAcf, ggtsdisplay\n```\n\n  1. Explore your chosen retail time series using these functions.\n  2. Can you spot any seasonality, cyclicity and trend?\n  3. What do you learn about the series?\n\n<a name=\"Lab3\"></a>\n\n### Lab Session 3\n\nDownload [the `Rmd` file](https://github.com/earowang/medascin17-tsvis/raw/master/lab/lab3.Rmd) for this lab session.\n\n1. Download the [billboard data](https://github.com/earowang/medascin17-tsvis/raw/master/data/billboard.csv). The `billboard` dataset contains the date a song first entered the Billboard Top 100 in 2000 and its rank over 76 weeks.\n2. Read the dataset into R and take a look at the data.\n3. Transform the data to the long data form named as `billboard_long`.\n4. [Bonus] Split the `billboard_long` to two separate datasets as `song` and `rank`. The `song` data will include `artist`, `track`, `time` and a new column called `id` assigning a unique identifier for each song. The `rank` data will include the `id`, `date`, `week`, `rank` columns. The `id` column is the key variable that maintains the linking between two datasets.\n\n<a name=\"Lab4\"></a>\n\n### Lab Session 4\n\nDownload [the `Rmd` file](https://github.com/earowang/medascin17-tsvis/raw/master/lab/lab4.Rmd) for this lab session.\n\n1. Download the [weather data](https://github.com/earowang/medascin17-tsvis/raw/master/data/weather_2016.csv).\n2. Read the dataset into R and tidy it up for visualising with `ggplot2` later.\n3. Write some `ggplot2` code to reproduce the plot shown on the slides.\n\n<a name=\"Lab5\"></a>\n\n### Lab Session 5\n\n  1. Use `ets()` to find the best ETS model for your retail data.\n\n    - What does the model choice tell you about the data?\n    - What do the smoothing parameters tell you about the trend and seasonality?\n    - Do the forecasts look reasonable?\n\n  2. Obtain up-to-date retail data from the [ABS website (Cat. 8501.0, Table 11)](https://goo.gl/HdrV0G), and compare your forecasts with the actual numbers. How good were the forecasts from the various models?\n\n<a name=\"Lab6\"></a>\n\n### Lab Session 6\n\nWe will now fit an ARIMA model for your retail data.\n\n  1. What Box-Cox transformation would you select to stabilize the variance?\n\n  2. Use `auto.arima` to obtain a seasonal ARIMA model, and compare the forecasts with those you obtained earlier, and with the latest retail data.\n\n  3. Experiment with different Box-Cox transformations to see their effect on the chosen model and forecasts.\n\n\n<a name=\"Lab7\"></a>\n\n\n### Lab Session 7\n\nFor your retail time series:\n\n  1. Use the `accuracy` function to compare the forecasts obtained from your ETS and ARIMA models. Which is giving the best forecasts?\n\n  2. Repeat with forecasts obtained using `stlf` (with the same Box-Cox transformation as you used for the ARIMA model).\n\n  3. Repeat with forecasts obtained using `snaive` (there's no need for a transformation).\n\n  4. Which approach gives the best forecasts?\n\n\n<a name=\"Lab8\"></a>\n\n### Lab Session 8\n\n  1. Use `ets` to find the best model for your retail data and record the training set MAPE.\n  1. We will now check how much larger the MAPE is on out-of-sample data using time series cross-validation. The following code will compute the result. Replace `???` with the appropriate values for your ETS model.\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    fets <- function(x, h, model=\"ZZZ\", damped=NULL, ...) {\n      forecast(ets(x, model=model, damped=damped), h=h)\n    }\n    e <- tsCV(mytimeseries, fets, model=???, damped=???)\n    pe <- 100*e/mytimeseries\n    sqrt(mean(pe^2, na.rm=TRUE))\n    ```\n    :::\n\n\n  1. Plot `pe` using `autoplot` and ``ggAcf``. Do they look uncorrelated and homoskedastic?\n\n  1. In practice, we will not know the best model on the whole data set  until we observe all the data. So a more realistic analysis would be to allow `ets` to select a different model each time through the loop. Calculate the MAPE using this approach.  (Warning: there a lot of models to fit, so this will take a while.)\n\n  1. How do the MAPE values compare? Does the re-selection of a model at each step make much difference?\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}